# Bloomberg Data Crawler - Environment Configuration Template
# Copy this file to .env and fill in your actual credentials
# NEVER commit .env file to version control

# ==============================================================================
# Bright Data Configuration (REQUIRED)
# ==============================================================================
# Get your API token from: https://brightdata.com/cp/zones
BRIGHT_DATA_TOKEN=your_customer_id_here
BRIGHT_DATA_ZONE=bloomberg
BRIGHT_DATA_HOST=brd.superproxy.io
BRIGHT_DATA_PORT=33335

# ==============================================================================
# Cost Management
# ==============================================================================
# Total budget in USD (default: $5.50)
TOTAL_BUDGET=5.50

# Cost per Bloomberg request in USD (default: $0.0015)
COST_PER_REQUEST=0.0015

# Safety margin as decimal (10% = 0.10)
SAFETY_MARGIN=0.10

# Alert when budget usage exceeds this threshold (80% = 0.80)
ALERT_THRESHOLD=0.80

# ==============================================================================
# External APIs (OPTIONAL)
# ==============================================================================
# Finnhub API for fallback financial data
# Get free API key from: https://finnhub.io/
FINNHUB_API_KEY=

# Alpha Vantage API for alternative data source
# Get free API key from: https://www.alphavantage.co/
ALPHA_VANTAGE_API_KEY=

# API request timeout in seconds
REQUEST_TIMEOUT=30

# ==============================================================================
# Cache Configuration
# ==============================================================================
# Cache time-to-live in seconds (900 = 15 minutes)
CACHE_TTL_SECONDS=900

# Data directory path (relative or absolute)
DATA_DIR=data

# Cache directory for raw responses
CACHE_DIR=cache

# ==============================================================================
# Scheduler Configuration
# ==============================================================================
# Update interval in seconds (900 = 15 minutes)
UPDATE_INTERVAL_SECONDS=900

# Enable automatic updates (true/false)
AUTO_UPDATE_ENABLED=true

# Maximum retry attempts for failed requests
MAX_RETRIES=3

# Delay between retries in seconds
RETRY_DELAY_SECONDS=5

# ==============================================================================
# Logging Configuration
# ==============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log directory path
LOG_DIR=logs

# Log file name
LOG_FILE=bloomberg_crawler.log

# Maximum log file size in bytes (10485760 = 10MB)
MAX_LOG_SIZE=10485760

# Number of backup log files to keep
BACKUP_COUNT=5
